{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f5a7745",
   "metadata": {},
   "source": [
    "## Inference images conditioned with prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581ce289",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tuneavideo.pipelines.pipeline_tuneavideo import TuneAVideoPipeline\n",
    "from tuneavideo.models.unet import UNet3DConditionModel\n",
    "from tuneavideo.util import save_videos_grid\n",
    "import torch\n",
    "\n",
    "pretrained_model_path = \"./checkpoints/CompVis/stable-diffusion-v1-4\"\n",
    "my_model_path = \"outputs/supewoman-talking5\"\n",
    "prompt = \"a woman, wearing Batman's mask, is talking\"\n",
    "\n",
    "unet = UNet3DConditionModel.from_pretrained(my_model_path, subfolder='unet', torch_dtype=torch.float16).to('cuda')\n",
    "pipe = TuneAVideoPipeline.from_pretrained(pretrained_model_path, unet=unet, torch_dtype=torch.float16).to(\"cuda\")\n",
    "pipe.enable_xformers_memory_efficient_attention()\n",
    "pipe.enable_vae_slicing()\n",
    "\n",
    "ddim_inv_latent = torch.load(f\"{my_model_path}/inv_latents/ddim_latent-500.pt\").to(torch.float16)\n",
    "video = pipe(prompt, latents=ddim_inv_latent, video_length=24, height=512, width=512, num_inference_steps=100, guidance_scale=12.5).videos\n",
    "\n",
    "save_videos_grid(video, f\"./{prompt}.gif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5577e71c",
   "metadata": {},
   "source": [
    "# Process the generated images (tif) and make new video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b89c134-dce0-4001-b5a1-320908b63dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic information about the input video ./data/videos/demo_input.mp4:\n",
      "                  FPS: 25.0\tDuration: 5.53\t                  Total frames: 138\n",
      "Moviepy - Building video wonderwoman.mp4.\n",
      "MoviePy - Writing audio in wonderwomanTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video wonderwoman.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready wonderwoman.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "from video_process import VideoProcess\n",
    "\n",
    "\n",
    "name = 'wonderwoman'\n",
    "original_vid = './data/videos/demo_input.mp4'\n",
    "generated_gifs = f'./data/gifs/{name}.gif'\n",
    "vp = VideoProcess(original_vid, generated_gifs)\n",
    "\n",
    "# get information (PFS, duration, frames) about the input video \n",
    "print(vp)\n",
    "vp.video(f'{name}.mp4') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d8ea12",
   "metadata": {},
   "source": [
    "### Convert the orginal video to gif (same dim as the generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a48aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "vp.mp42gifs(outname='input_demo.gif', resize=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NERSC Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
